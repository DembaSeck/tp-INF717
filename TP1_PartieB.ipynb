{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a946e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "471f8852",
   "metadata": {},
   "source": [
    "Plan d’organisation pour la Partie B, inspiré de la Partie A, pour entraîner un classifieur de priorité avec BARThez.  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Membres de l’équipe\n",
    "   \n",
    "- Demba Seck secd1700  \n",
    "- Cheikh Tidiane Gueye\n",
    "- Fatou Bintou Boye boyf7012 \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Télécharger et préparer le jeu de données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b053405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = 'https://drive.google.com/uc?export=download&id=13ZfF8DjSvqPJkrY93GJTK2l14IwLVLZ0'\n",
    "urllib.request.urlretrieve(url, 'IT_Support_Tickets_FR_200.csv')\n",
    "print('Téléchargement terminé !')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcc3df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Charger le DataFrame et afficher les colonnes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f6855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"IT_Support_Tickets_FR_200.csv\")\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1c5e3d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Préparer les données pour la classification de priorité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b51e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les colonnes inutiles\n",
    "colonnes_a_retirer = ['ID Ticket', 'Date', 'Client', 'Type de problème']\n",
    "df_priorite = df.drop(columns=colonnes_a_retirer)\n",
    "df_priorite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c92ea",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Encoder la priorité\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c33a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encodeur_priorite = LabelEncoder()\n",
    "df_priorite['Classe'] = encodeur_priorite.fit_transform(df_priorite['Priorité'])\n",
    "df_priorite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad434b3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Split train/val/test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59948670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_priorite['Description']\n",
    "y = df_priorite['Classe']\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b89b1b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Tokenizer BARThez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"moussaKam/barthez\")\n",
    "X_train_list = X_train.tolist()\n",
    "X_val_list = X_val.tolist()\n",
    "X_test_list = X_test.tolist()\n",
    "\n",
    "train_tokens = tokenizer(X_train_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "val_tokens = tokenizer(X_val_list, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "test_tokens = tokenizer(X_test_list, padding=True, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc437e3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Dataset PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6deb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class TicketDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_dataset = TicketDataset(train_tokens, y_train.tolist())\n",
    "val_dataset = TicketDataset(val_tokens, y_val.tolist())\n",
    "test_dataset = TicketDataset(test_tokens, y_test.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67e7432",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 9. Modèle BARThez pour classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8143ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "n_classes = len(df_priorite['Classe'].unique())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"moussaKam/barthez\", num_labels=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0804ce77",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 10. Entraînement du modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    preds = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e02d3e1",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 11. Lancer l’entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141d05f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 12. Évaluer sur le jeu de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2722c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = trainer.evaluate(test_dataset)\n",
    "print(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4182dbc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 13. Afficher les prédictions (optionnel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "logits = predictions.predictions\n",
    "if isinstance(logits, tuple):\n",
    "    logits = logits[0]\n",
    "pred_labels = np.argmax(logits, axis=1)\n",
    "true_labels = predictions.label_ids\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    print(\"Description:\", X_test.iloc[i])\n",
    "    print(\"True label:\", encodeur_priorite.inverse_transform([true_labels[i]])[0])\n",
    "    print(\"Predicted:\", encodeur_priorite.inverse_transform([pred_labels[i]])[0])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58283998",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 14. Résultats (cellule texte)\n",
    "Indiquez ici le score F1 obtenu sur le jeu de test.\n",
    "\n",
    "---\n",
    "\n",
    "Adapte chaque cellule selon tes besoins.  \n",
    "N’oublie pas d’expliquer chaque étape dans des cellules texte !"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
